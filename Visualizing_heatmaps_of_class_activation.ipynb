{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/unkn0wn27/anaconda3/envs/deep-learning-python-keras/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "model = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'elephants.png'\n",
    "# Python Imaging Library(PIL)\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# float32 numpy array of shape (224, 224, 3)\n",
    "x = image.img_to_array(img)\n",
    "# adds a dimiension to transform the array into a batch of size (1, 224, 224, 3)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "# preprocesses the batch (this does channel-wise color normalization)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n02504458', 'African_elephant', 0.8765623), ('n01871265', 'tusker', 0.11419991), ('n02504013', 'Indian_elephant', 0.009071713)]\n"
     ]
    }
   ],
   "source": [
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# african elephant entry prediction vector\n",
    "african_elephant_output = model.output[:, 386]\n",
    "\n",
    "# output feature map of the block5_conv3 layer, the last convolution layer in VGG16\n",
    "last_conv_layer = model.get_layer('block5_conv3')\n",
    "\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "# values of these two quantities, as Numpy arrays, given the sample image of two elephants\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7c2fc59d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('elephants_cam.png', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
